# BaseFAQ AI Architecture Proposal

## Executive Summary
This document defines how `BaseFaq.AI.Generation` and `BaseFaq.AI.Matching` should be added to BaseFAQ with minimal incremental changes while respecting the new AI service boundaries.

The proposal preserves the existing architecture model where possible:
- Existing API hosts remain composition roots.
- Existing `Business` modules continue using MediatR orchestration.
- Existing infrastructure conventions (auth, Sentry, Redis, RabbitMQ baseline) remain in place.

The proposal also applies the new constraints:
- `BaseFaq.AI` uses a dedicated database: `bf_ai_db`.
- `BaseFaq.AI` uses a dedicated persistence context (for example `AiDbContext`).
- `BaseFaq.AI` has no tenant model.
- No FK relationship exists between AI DB and FAQ DB.
- `BaseFaq.Faq` APIs communicate with `BaseFaq.AI` asynchronously via RabbitMQ.
- `BaseFaq.AI` processes requests, updates FAQ data through integration write flow, and publishes callback events so FAQ APIs know processing is done and ready.

The AI capability remains organized under:
- `BaseFaq.AI/Generation`
- `BaseFaq.AI/Matching`
- `BaseFaq.AI/Common`

## Recommended Architecture (Aligned to Existing BaseFAQ Model)
### Architectural assumptions
- No active production-grade queue consumers are currently implemented.
- AI generation and matching are delivered as AI services integrated with FAQ APIs through RabbitMQ.
- Existing folder conventions (`Api`, `Business`, `Test`) should be preserved.
- `BaseFaq.AI` does not use tenant resolution or tenant partitioning.

### Existing model to preserve
- API startup and middleware pattern in API host projects.
- Feature composition via extension methods in `Api/Extensions`.
- Application orchestration in Business projects with MediatR handlers.
- FAQ persistence ownership remains in `BaseFaq.Faq.Common.Persistence.FaqDb` (`FaqDbContext`) for FAQ domain data.
- Shared infrastructure utilities from `BaseFaq.Common.Infrastructure.*`.

### Target high-level model
- `Generation`: asynchronous workflow driven by RabbitMQ events and worker consumers.
- `Matching`: synchronous query path for end-user retrieval, with asynchronous background indexing/embedding refresh.
- `Common`: provider and vector abstractions shared by both modules.
- `Persistence split`:
  - AI lifecycle and operational state in `bf_ai_db` via AI context.
  - FAQ product data in FAQ DB via `FaqDbContext`.

## Current Solution Style + Incremental Additions
### Existing BaseFAQ components (unchanged)
- `BaseFaq.Faq.Portal.Api` and `BaseFaq.Faq.Public.Api` startup conventions.
- Existing middleware: auth, API error handling, Sentry.
- Existing `BaseFaq.Faq.Portal.Business.*` and `BaseFaq.Faq.Public.Business.*` patterns.
- Existing FAQ entity model and DB context ownership in `BaseFaq.Faq.Common.Persistence.FaqDb`.

### Existing components with additive changes only
- `BaseFaq.Faq.Portal.Api`:
  - Register AI generation feature in existing `AddFeatures(...)`.
  - Add generation endpoints through new Business module controllers.
- `BaseFaq.Faq.Public.Api`:
  - Register AI matching feature in existing `AddFeatures(...)`.
  - Add matching endpoints through new Business module controllers.
- `BaseFaq.Faq.Common.Persistence.FaqDb`:
  - Keep FAQ domain ownership.
  - Store only FAQ-side final data/state needed for product usage.
  - Do not store AI lifecycle state that belongs to `bf_ai_db`.

### New components (added)
- New AI projects under `BaseFaq.AI` only (no restructuring of existing modules).
- New worker processes for asynchronous generation and optional embedding refresh.
- New contracts shared for AI events and provider abstractions.
- New AI persistence layer with dedicated context and migrations for `bf_ai_db`.

## BaseFaq.AI.Generation and BaseFaq.AI.Matching Project Divisions
| Division | Responsibility | Recommended .NET technologies/libraries | Applicable patterns | Risks | Mitigations |
|---|---|---|---|---|---|
| API integration endpoints | Expose commands/queries in existing API model (`Portal` for generation, `Public` for matching) | ASP.NET Core controllers, existing auth middleware | Thin controller + application service | API bloat | Keep strict route namespace `api/faqs/ai/*` |
| Application orchestration layer | Validate input, coordinate workflows, dispatch commands/queries | MediatR, FluentValidation (optional) | CQRS, orchestration service | Business logic leakage into controllers | Keep orchestration in handlers/services only |
| AI processing worker/service | Consume generation jobs, call LLM provider, persist outputs in `bf_ai_db`, update FAQ data, emit ready/failure callbacks | Worker Service, RabbitMQ consumer, Polly, HttpClientFactory | Async consumer, retry/circuit-breaker | Duplicate side effects | Idempotency keys + dedupe store + exactly-once business semantics |
| Domain rules for FAQ generation lifecycle | Enforce status transitions and review gates | Domain services + enums + guard methods | State machine | Invalid transitions | Transition guard + integration tests |
| Persistence and FAQ versioning | Split ownership: AI state in `bf_ai_db`; final FAQ versions in FAQ DB | EF Core, Npgsql, existing migration flow | Explicit integration write flow + eventual consistency | Cross-DB consistency drift | Correlation IDs, retries, compensating status, callback confirmation |
| Messaging/events integration | Decouple request/processing/completion and status notifications | RabbitMQ (MassTransit optional abstraction) | Event-driven architecture, outbox/inbox | Duplicate delivery | Idempotency keys + processed-message store |
| Security and secret management | Secure provider keys and prevent secret leakage | .NET config providers, User Secrets (dev), cloud secret manager | Secret abstraction + rotation | Secret exposure | Vault-only in non-dev + redaction filters |
| Observability and operations | Visibility across APIs, workers, broker, DB, provider calls | Sentry (existing), OpenTelemetry, HealthChecks, structured logs | Correlation tracing + SLO monitoring | Blind failure modes | End-to-end tracing + alerting thresholds |
| Prompt governance and answer quality controls | Prompt versioning, policy checks, publication gates | Prompt registry (JSON/YAML + DB ref), evaluation runner (optional) | Prompt-as-code + human-in-the-loop | Hallucinations/quality drift | Quality rubric + approval workflow + fallback |

## Event Flow (Step-by-Step)
### End-to-end
1. Client calls `POST /api/faqs/ai/generation-jobs` (Portal API).
2. FAQ API validates request/user context and stores FAQ-side request metadata as `Requested`.
3. FAQ API publishes `FaqGenerationRequestedV1` with correlation and idempotency metadata to RabbitMQ.
4. AI Generation worker consumes request event.
5. Worker creates/updates AI job in `bf_ai_db` and sets status `Processing`.
6. Worker loads prompt profile and source context.
7. Worker calls provider (`OpenAI`/`Azure OpenAI`) with retries and timeout policy.
8. Worker applies quality checks and business rules.
9. Worker persists AI artifacts and lifecycle details in `bf_ai_db`.
10. Worker updates FAQ data in FAQ DB through integration write flow (`FaqDbContext`) with final approved payload.
11. Worker sets final AI job status:
   - `AwaitingReview` (if review gate applies), or
   - `Completed` / `Published`, or
   - `Failed`.
12. Worker publishes callback event (`FaqGenerationReadyV1` or `FaqGenerationFailedV1`) to RabbitMQ.
13. FAQ API-side consumer receives callback and marks request as done/failed and ready to use.
14. The cycle repeats for subsequent generation/matching requests.

## Synchronous vs Asynchronous Integration
### Use synchronous when
- The caller needs immediate answer and bounded latency is acceptable.
- Example: FAQ matching query in Public API (`search/match` path).
- Timeout budget should be strict; fallback to lexical match if vector/provider unavailable.

### Use asynchronous when
- Work is compute-heavy, long-running, expensive, or failure-prone.
- Example: FAQ generation, re-generation, bulk embedding refresh.
- API should return `202 Accepted` with job identifier and polling/subscription mechanism.

### Rule of thumb
- `Generation`: async by default.
- `Matching`: sync query path + async index maintenance.

## RabbitMQ and MassTransit Evaluation
### Scenario A: Use both together (recommended if already standardized)
- Use RabbitMQ as transport broker.
- Use MassTransit as .NET messaging abstraction/runtime.

Pros:
- Faster delivery for consumers/producers.
- Built-in middleware for retry, delayed retry, error queues, topology.
- Better developer ergonomics and observability hooks.

Cons:
- Additional abstraction layer to operate and understand.

### Scenario B: Use only RabbitMQ client library
Pros:
- Lower abstraction overhead.
- Full control of broker semantics.

Cons:
- More boilerplate for retries, correlation, poison handling, and instrumentation.
- Higher maintenance and inconsistency risk across services.

### Scenario C: Use only MassTransit (without RabbitMQ)
- Not aligned because RabbitMQ is the required communication backbone in this architecture.
- Would require selecting another transport and operating model.

### Trade-offs
| Option | Complexity | Resilience | Observability | Operational cost |
|---|---|---|---|---|
| RabbitMQ + MassTransit | Medium | High | High | Medium |
| RabbitMQ only | Medium-High (app code) | Medium | Medium-Low | Medium |
| Alternative transport with MassTransit only | Medium-High (migration) | Medium-High | Medium-High | Medium-High |

Recommended for BaseFAQ:
- Keep RabbitMQ as broker and service communication channel.
- Use MassTransit where it accelerates delivery and reliability in .NET services.

## Idempotency, Retry, DLQ, Tracing, Monitoring
### Idempotency strategy
- Require `Idempotency-Key` on generation command API.
- Persist unique key at job creation (`FaqId + IdempotencyKey` unique index, or `JobId` uniqueness).
- Consumer dedupe:
  - Store processed `MessageId` + handler name.
  - Skip if already processed.

### Retry policy
- Transport/consumer-level retries for transient infrastructure issues.
- Provider-level retries with exponential backoff + jitter (429/5xx/timeouts).
- FAQ DB integration write retries with safe idempotent upsert semantics.
- No retries for validation/domain errors.

### Dead-letter queue strategy
- Route poison messages to `_error` queues.
- Add AI-specific quarantine queue for messages exceeding retry policy.
- Operational runbook:
  - Inspect cause.
  - Patch/redeploy.
  - Replay safe messages with dedupe check.

### Distributed tracing
- Propagate `traceparent`, `CorrelationId`, `CausationId` through API -> broker -> worker -> AI DB/FAQ DB/provider.
- Add spans for:
  - API command handling.
  - Event publish/consume.
  - Provider API call.
  - AI DB persistence.
  - FAQ DB integration write.

### Monitoring and alerting
- Metrics:
  - Job throughput and completion rate.
  - Failure rate by error code.
  - Queue depth and message age.
  - p95 and p99 generation duration.
  - Matching latency.
  - FAQ update latency after AI completion.
- Alerts:
  - Queue lag threshold exceeded.
  - Failure ratio above baseline.
  - DLQ growth.
  - Provider error spikes / rate limiting spikes.
  - Repeated callback publish failures.

## OpenAI API Key Security Strategy
### Secret manager
- Development: .NET User Secrets.
- Production: managed secret manager (Azure Key Vault / AWS Secrets Manager / GCP Secret Manager).
- Never store provider keys in repository `appsettings*.json`.

### Key rotation
- Support active/standby key references.
- Rotate regularly (time-based) and on incident trigger.
- Use `IOptionsMonitor` or equivalent config reload for zero-downtime key switch.

### Log masking and no leakage
- Redact:
  - `Authorization` headers.
  - API keys and tokens.
  - Prompt fragments containing sensitive content.
- Disable verbose provider request/response logs in production.
- Add logging guard middleware/sinks with explicit masking rules.

## Implementation Plan by Phase
### Phase 1: MVP
- Create AI project skeleton under `BaseFaq.AI`.
- Implement generation command + async worker processing.
- Implement generation status endpoint.
- Add minimum AI persistence model in `bf_ai_db` for job + generated artifacts.
- Implement FAQ integration write flow (`BaseFaq.AI` -> FAQ DB write path) + callback event.
- Implement matching endpoint with basic vector + fallback search.
- Add integration tests for happy-path generation and matching.

### Phase 2: Production Hardening
- Add idempotency enforcement and consumer dedupe store.
- Configure robust retry and DLQ policies.
- Add full tracing and alerting.
- Introduce prompt governance and quality gates.
- Enforce secret manager in non-dev environments.
- Add reconciliation job for AI done but FAQ callback not acknowledged.

### Phase 3: Scale
- Separate workers by workload type (generation vs embedding/index refresh).
- Introduce batching and adaptive concurrency controls.
- Add cost controls and provider routing strategy.
- Improve relevance quality via hybrid retrieval and re-ranking.

## Practical Artifacts
### Event contract examples
```csharp
public record FaqGenerationRequestedV1(
    Guid EventId,
    Guid CorrelationId,
    Guid JobId,
    Guid RequestedByUserId,
    string IdempotencyKey,
    Guid FaqId,
    string Language,
    string PromptProfile,
    DateTime OccurredUtc);

public record FaqGenerationReadyV1(
    Guid EventId,
    Guid CorrelationId,
    Guid JobId,
    Guid FaqVersionId,
    bool RequiresHumanReview,
    DateTime OccurredUtc);

public record FaqGenerationFailedV1(
    Guid EventId,
    Guid CorrelationId,
    Guid JobId,
    string ErrorCode,
    string ErrorMessage,
    DateTime OccurredUtc);
```

### Solution/project folder structure
```text
dotnet
  /BaseFaq.AI.Generation.Api
  /BaseFaq.AI.Generation.Business.Generation
  /BaseFaq.AI.Generation.Business.Worker
  /BaseFaq.AI.Generation.Test.IntegrationTests
  /BaseFaq.AI.Matching.Api
  /BaseFaq.AI.Matching.Business.Matching
  /BaseFaq.AI.Matching.Business.Worker
  /BaseFaq.AI.Matching.Test.IntegrationTests
  /BaseFaq.AI.Common.Providers
  /BaseFaq.AI.Common.VectorStore
  /BaseFaq.AI.Common.Contracts
```

Suggested concrete project names:
```text
dotnet/BaseFaq.AI.Generation.Api/BaseFaq.AI.Generation.Api.csproj
dotnet/BaseFaq.AI.Generation.Business.Generation/BaseFaq.AI.Generation.Business.Generation.csproj
dotnet/BaseFaq.AI.Generation.Business.Worker/BaseFaq.AI.Generation.Business.Worker.csproj
dotnet/BaseFaq.AI.Generation.Test.IntegrationTests/BaseFaq.AI.Generation.Test.IntegrationTests.csproj

dotnet/BaseFaq.AI.Matching.Api/BaseFaq.AI.Matching.Api.csproj
dotnet/BaseFaq.AI.Matching.Business.Matching/BaseFaq.AI.Matching.Business.Matching.csproj
dotnet/BaseFaq.AI.Matching.Business.Worker/BaseFaq.AI.Matching.Business.Worker.csproj
dotnet/BaseFaq.AI.Matching.Test.IntegrationTests/BaseFaq.AI.Matching.Test.IntegrationTests.csproj

dotnet/BaseFaq.AI.Common.Providers/BaseFaq.AI.Common.Providers.csproj
dotnet/BaseFaq.AI.Common.VectorStore/BaseFaq.AI.Common.VectorStore.csproj
dotnet/BaseFaq.AI.Common.Contracts/BaseFaq.AI.Common.Contracts.csproj
```

## Main Risks and Mitigations
| Risk | Impact | Mitigation |
|---|---|---|
| Cross-database update inconsistency (`bf_ai_db` success, FAQ DB write failure) | Callback may not represent real final state | Retry with idempotent upsert, reconciliation worker, failure callback if threshold exceeded |
| Duplicate event delivery | Duplicate generation/persistence | Idempotency keys + processed-message table + unique constraints |
| LLM quality drift | Low trust in generated FAQs | Prompt versioning + quality checks + human approval gate |
| Provider outages/rate limits | Latency and failures | Retry/backoff, circuit breaker, fallback model strategy |
| Secret leakage | Security incident | Secret manager, strict redaction, no secrets in source config |
| Queue backlog growth | SLA degradation | Queue depth alerts, scaling workers, backpressure controls |

## Final Technical Checklist
- [x] `BaseFaq.AI` root folder and projects created.
- [x] `Generation` and `Matching` projects follow existing `Api/Business/Test` conventions.
- [x] Existing API hosts register new AI features without changing current boundaries.
- [x] AI lifecycle entities and migrations added to `bf_ai_db` persistence.
- [x] `AiDbContext` separated and wired independently from `FaqDbContext`.
- [x] No FK relationship exists between AI and FAQ databases.
- [x] Async generation event flow implemented end-to-end through RabbitMQ.
- [x] Callback flow implemented (`Ready`/`Failed`) and consumed by FAQ Portal API.
- [x] FAQ integration write flow from AI services to FAQ DB is idempotent and validated.
- [ ] Matching endpoint implemented with synchronous response, it doenst need fallback behavior and consumed by FAQ Public API only the request.
- [ ] Idempotency key support and dedupe table in place.
- [ ] Retry and DLQ policies configured and validated.
- [ ] Distributed tracing across API, broker, worker, AI DB, FAQ DB, provider enabled.
- [ ] Monitoring dashboard and alerts configured.
- [ ] Secret manager integration and key rotation process implemented.
- [ ] Logging redaction rules validated (no key leakage).
- [ ] Prompt governance and quality gate process documented.
- [ ] MVP, hardening, and scale backlog items created and tracked.
